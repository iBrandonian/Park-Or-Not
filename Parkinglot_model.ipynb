{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Parkinglot_model.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"8uikrCdt8KSQ","executionInfo":{"status":"ok","timestamp":1616890182643,"user_tz":300,"elapsed":2581,"user":{"displayName":"Moriam Godo","photoUrl":"","userId":"16815271678542822598"}}},"source":["# http://cnrpark.it/\n","# importing all the packages need to build a Convolutional neural network (CNN) model\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPool2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","\n","import requests #For HTTP Post\n","import os\n","\n","batch_size = 32             # number of samples or examples the algorithm takes at a time\n","learning_rate = 0.0001      # a parameter that is tuned ti optimize the algorithm\n","epoch = 5                   # # number of times over all the dataset"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hxIC2OsNQV8","executionInfo":{"status":"ok","timestamp":1616890244227,"user_tz":300,"elapsed":44144,"user":{"displayName":"Moriam Godo","photoUrl":"","userId":"16815271678542822598"}},"outputId":"1d5227a6-dc6c-4d50-cfab-86e6fb927136"},"source":["# mount google drive to access data in folder\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ezlWv9665Oj","executionInfo":{"status":"ok","timestamp":1616875299565,"user_tz":300,"elapsed":594,"user":{"displayName":"Moriam Godo","photoUrl":"","userId":"16815271678542822598"}},"outputId":"e2a8bd92-50d7-4377-8865-8eab1b638934"},"source":["## Image dimensions are 113 X 150 pixels\n","print('Number of Images in Park_train: ',len(os.listdir(\"/content/drive/My Drive/parkingData/park_train\")))\n","print('Number of Images in Park_test: ',len(os.listdir(\"/content/drive/My Drive/parkingData/park_test\")))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of Images in Park_train:  5711\n","Number of Images in Park_test:  1161\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ypk2OsCH8aGg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616896315199,"user_tz":300,"elapsed":2148251,"user":{"displayName":"Moriam Godo","photoUrl":"","userId":"16815271678542822598"}},"outputId":"2db32df1-7429-46c3-ff1c-d884a1f368c3"},"source":["#Initiate a model\n","model = Sequential()\n","\n","# extraction the learnable features and reducing dimension \n","model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(113,150,3)))\n","model.add(MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n","\n","model.add(Conv2D(32,3,3,activation='relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64,3,3,activation='relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","\n","# Preparing the images for input in ANN by converting to single column\n","model.add(Flatten())\n","model.add(Dense(128,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))\n","\n","opt = keras.optimizers.Adam(learning_rate=learning_rate)\n","model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n","\n","model.summary()\n","\n","#Image Augmentation - Processing and tranforming the image to generate more images\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","datagenerator_train = ImageDataGenerator(rescale=1./255,\n","                                        shear_range=0.2,\n","                                         zoom_range=0.2,\n","                                         horizontal_flip = True,\n","                                         validation_split=0.2)\n","\n","datagenerator_test = ImageDataGenerator(rescale=1./255)\n","\n","# training the dataset\n","train_dataset = datagenerator_train.flow_from_directory(\"/content/drive/My Drive/parkingData\",\n","                                                        target_size = (113, 150),\n","                                                        batch_size = batch_size,\n","                                                        class_mode = 'binary',\n","                                                       subset='training')\n","\n","test_dataset = datagenerator_train.flow_from_directory(\"/content/drive/My Drive/parkingData\",\n","                                                        target_size = (113, 150),\n","                                                        batch_size = batch_size,\n","                                                        class_mode = 'binary',\n","                                                      subset='validation')\n","\n","# Fit the model\n","model.fit(train_dataset,\n","          batch_size = batch_size,\n","          #steps_per_epoch = len(train_dataset) // batch_size,\n","          epochs = 5,\n","          verbose = 1,\n","          validation_data = test_dataset)\n","          #validation_steps = 1374)   \n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 111, 148, 32)      896       \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 110, 147, 32)      0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 36, 49, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 18, 24, 32)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 6, 8, 64)          18496     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 3, 4, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 768)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               98432     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 127,201\n","Trainable params: 127,201\n","Non-trainable params: 0\n","_________________________________________________________________\n","Found 5498 images belonging to 2 classes.\n","Found 1374 images belonging to 2 classes.\n","Epoch 1/5\n","172/172 [==============================] - 1567s 9s/step - loss: 0.5167 - accuracy: 0.8179 - val_loss: 0.4268 - val_accuracy: 0.8311\n","Epoch 2/5\n","172/172 [==============================] - 143s 831ms/step - loss: 0.4544 - accuracy: 0.8315 - val_loss: 0.3700 - val_accuracy: 0.8311\n","Epoch 3/5\n","172/172 [==============================] - 144s 836ms/step - loss: 0.4186 - accuracy: 0.8360 - val_loss: 0.3232 - val_accuracy: 0.8399\n","Epoch 4/5\n","172/172 [==============================] - 143s 830ms/step - loss: 0.3877 - accuracy: 0.8489 - val_loss: 0.3126 - val_accuracy: 0.8581\n","Epoch 5/5\n","172/172 [==============================] - 144s 834ms/step - loss: 0.3901 - accuracy: 0.8330 - val_loss: 0.3012 - val_accuracy: 0.8661\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f097e67d490>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ebXT29Zqhjw1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616904125635,"user_tz":300,"elapsed":2349,"user":{"displayName":"Moriam Godo","photoUrl":"","userId":"16815271678542822598"}},"outputId":"1aea1f74-a063-4c05-9a9b-3e9ac20ae38c"},"source":["import numpy as np\n","from keras.preprocessing import image\n","import random\n","\n","parkData = '' #String to append to POST\n","parkUrl = 'http://parkdata.us.to/parkdata.php' #Link to web server\n","myobj = {'parkdata': parkData} #HTTP Post parameters\n","\n","# To classify new image\n","pic = \"/content/drive/My Drive/parkingData/park_test/20150708_0830_26.jpg\"\n","new_img = image.load_img(pic,target_size = (113, 150))\n","\n","#Get random image from file\n","\n","path = r\"/content/drive/My Drive/parkingData/park_train\"\n","random_filename = random.choice([\n","   x for x in os.listdir(path)\n","   if os.path.isfile(os.path.join(path, x))])\n","#print(random_filename)\n","\n","#new_img = image.load_img(random_filename,target_size = (113, 150))\n","#Process the image\n","new_img = image.img_to_array(new_img)\n","new_img = np.expand_dims(new_img, axis=0)\n","\n","#Predict new image\n","result = model.predict(new_img)\n","print(result)    # Predicts the new image as 1 occupied and 0 free\n","\n","train_dataset.class_indices\n","if result[0][0] == 1:\n","  output = 'It is occupied!'\n","  parkData += '1\\n'\n","  \n","else:\n","  output = 'It is available!'\n","  parkData += '0\\n'\n","\n","print(output)\n","x = requests.post(parkUrl, data = myobj)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["20150703_1430_38.jpg\n","[[1.]]\n","It is occupied!\n"],"name":"stdout"}]}]}